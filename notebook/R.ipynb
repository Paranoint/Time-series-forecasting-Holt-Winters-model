{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb769ef-5dfe-4673-a77a-8243bb704dfc",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Install/load required packages\n",
    "if (!requireNamespace(\"forecast\", quietly = TRUE)) install.packages(\"forecast\", repos = \"https://cloud.r-project.org\")\n",
    "if (!requireNamespace(\"jsonlite\", quietly = TRUE)) install.packages(\"jsonlite\", repos = \"https://cloud.r-project.org\")\n",
    "if (!requireNamespace(\"pryr\", quietly = TRUE)) install.packages(\"pryr\", repos = \"https://cloud.r-project.org\")\n",
    "\n",
    "library(forecast)\n",
    "library(jsonlite)\n",
    "library(pryr)\n",
    "\n",
    "# Directories\n",
    "project_root <- normalizePath(file.path(getwd(), \"..\"))\n",
    "data_dir <- file.path(project_root, \"data\")\n",
    "out_dir <- file.path(project_root, \"output\", \"r\")\n",
    "if (!dir.exists(out_dir)) dir.create(out_dir, recursive = TRUE)\n",
    "\n",
    "# Selection pattern (glob)\n",
    "name_glob <- \"*.csv\"  # e.g., \"linear_*_*.csv\" or \"season_*_*.csv\"\n",
    "\n",
    "# Config (defaults; can be overridden per-file)\n",
    "train_ratio <- 0.7          # used only if you switch back from fixed 30%\n",
    "ycol <- \"y\"\n",
    "seasonal_periods <- NA      # default; per-file override for season_*\n",
    "trend_type <- \"A\"          # \"A\" additive, \"N\" none\n",
    "seasonal_type <- \"N\"       # default seasonal letter if seasonal is enabled\n",
    "\n",
    "read_series <- function(path, ycol = \"y\") {\n",
    "  df <- tryCatch({\n",
    "    read.csv(path, stringsAsFactors = FALSE)\n",
    "  }, error = function(e) stop(e))\n",
    "  if (!(ycol %in% colnames(df))) stop(sprintf(\"Column '%s' not found in %s\", ycol, path))\n",
    "  series <- df[[ycol]]\n",
    "  # keep numeric index for saving\n",
    "  return(list(series = as.numeric(series), df = df))\n",
    "}\n",
    "\n",
    "save_forecast_csv <- function(stem, idx_vals, yhat, out_dir, seasonal_periods_current) {\n",
    "  out_path <- file.path(out_dir, sprintf(\"%s_hw_h%d_s%d.csv\",\n",
    "                                         stem, length(yhat),\n",
    "                                         ifelse(is.na(seasonal_periods_current), 0, seasonal_periods_current)))\n",
    "  write.csv(data.frame(index = idx_vals, value = as.numeric(yhat)), out_path, row.names = FALSE)\n",
    "  return(out_path)\n",
    "}\n",
    "\n",
    "process_one <- function(csv_path) {\n",
    "  sr <- read_series(csv_path, ycol)\n",
    "  y <- sr$series\n",
    "  n <- length(y)\n",
    "\n",
    "  # Enforce exactly 30% test\n",
    "  h <- max(1L, round(n * 0.3))\n",
    "  split <- n - h\n",
    "  train <- y[1:split]\n",
    "  test <- if (split < n) y[(split + 1):n] else numeric(0)\n",
    "\n",
    "  # Detect seasonal files by prefix \"season_\" and set local seasonal config\n",
    "  stem <- tools::file_path_sans_ext(basename(csv_path))\n",
    "  is_season <- startsWith(stem, \"season_\")\n",
    "  sp_local <- if (is_season) 24 else if (!is.na(seasonal_periods) && seasonal_periods > 1) seasonal_periods else NA\n",
    "  seasonal_type_local <- if (is_season) \"A\" else seasonal_type\n",
    "\n",
    "  # Build ts object for ETS with local frequency\n",
    "  if (!is.na(sp_local) && sp_local > 1) {\n",
    "    train_ts <- ts(train, frequency = sp_local)\n",
    "  } else {\n",
    "    train_ts <- ts(train)\n",
    "  }\n",
    "\n",
    "  # Model string: error, trend, seasonal (simple fixed letters)\n",
    "  model_str <- sprintf(\"%s%s%s\", trend_type, trend_type, ifelse(is.na(sp_local), \"N\", seasonal_type_local))\n",
    "\n",
    "  # Measure time and memory using system.time + pryr::mem_change\n",
    "  fit_mem_change <- mem_change({\n",
    "    fit_time <- system.time({\n",
    "      fit <- tryCatch({\n",
    "        forecast::ets(train_ts, model = model_str)\n",
    "      }, error = function(e) {\n",
    "        forecast::ets(train_ts)\n",
    "      })\n",
    "    })\n",
    "  })\n",
    "  train_time_s <- as.numeric(fit_time[\"elapsed\"])\n",
    "  mem_used_fit_bytes <- as.numeric(fit_mem_change)\n",
    "\n",
    "  # Forecast\n",
    "  pred_mem_change <- mem_change({\n",
    "    pred_time <- system.time({\n",
    "      fcast <- if (h > 0) forecast::forecast(fit, h = h) else NULL\n",
    "    })\n",
    "  })\n",
    "  predict_time_s <- as.numeric(pred_time[\"elapsed\"])\n",
    "  mem_used_pred_bytes <- as.numeric(pred_mem_change)\n",
    "\n",
    "  # Prepare outputs\n",
    "  idx_vals <- if (h > 0) (split):(split + h - 1) else integer(0)\n",
    "  out_path <- if (!is.null(fcast)) save_forecast_csv(stem, idx_vals, fcast$mean, out_dir, sp_local)\n",
    "              else file.path(out_dir, sprintf(\"%s_hw_h0_s%d.csv\", stem, ifelse(is.na(sp_local), 0, sp_local)))\n",
    "\n",
    "  # Metrics\n",
    "  if (h > 0) {\n",
    "    y_true <- test\n",
    "    y_pred <- as.numeric(fcast$mean)\n",
    "    err <- y_true - y_pred\n",
    "    rmse <- sqrt(mean(err^2))\n",
    "    mae <- mean(abs(err))\n",
    "    mape <- suppressWarnings(mean(abs(err / ifelse(y_true == 0, NA, y_true)), na.rm = TRUE) * 100)\n",
    "  } else {\n",
    "    rmse <- NA; mae <- NA; mape <- NA; y_pred <- NULL\n",
    "  }\n",
    "\n",
    "  metrics <- list(\n",
    "    file = normalizePath(csv_path),\n",
    "    n_total = n,\n",
    "    n_train = length(train),\n",
    "    n_test = h,\n",
    "    train_time_s = train_time_s,\n",
    "    predict_time_s = predict_time_s,\n",
    "    mem_used_fit_bytes = as.integer(mem_used_fit_bytes),\n",
    "    mem_used_pred_bytes = as.integer(mem_used_pred_bytes),\n",
    "    rmse = ifelse(is.na(rmse), NA, as.numeric(rmse)),\n",
    "    mae = ifelse(is.na(mae), NA, as.numeric(mae)),\n",
    "    mape_pct = ifelse(is.na(mape), NA, as.numeric(mape)),\n",
    "    forecast_csv = normalizePath(out_path)\n",
    "  )\n",
    "\n",
    "  metrics_path <- file.path(out_dir, sprintf(\"%s_hw_metrics.json\", stem))\n",
    "  write(jsonlite::toJSON(metrics, pretty = TRUE, auto_unbox = TRUE), metrics_path)\n",
    "\n",
    "  # Plot on a common axis 1..n\n",
    "  png(file.path(out_dir, sprintf(\"%s_hw_plot_h%d.png\", stem, h)), width = 900, height = 450)\n",
    "  x_full <- 1:n\n",
    "  y_full <- c(train, test)\n",
    "  plot(x_full, y_full, type = \"n\",\n",
    "       main = sprintf(\"Holt-Winters forecast (%s)\", basename(csv_path)),\n",
    "       xlab = \"t\", ylab = \"y\")\n",
    "  lines(1:split, train, type = \"o\", col = \"black\")\n",
    "  if (h > 0) {\n",
    "    lines((split + 1):n, test, type = \"o\", col = \"red\")\n",
    "    lines((split + 1):n, y_pred, type = \"o\", col = \"blue\")\n",
    "  }\n",
    "  abline(v = split, col = \"gray60\", lty = 2)\n",
    "  legend(\"topleft\",\n",
    "         legend = c(\"train\", \"test\", \"forecast\", sprintf(\"test≈%.0f%%\", 100 * h / n)),\n",
    "         col = c(\"black\", \"red\", \"blue\", \"gray60\"),\n",
    "         lty = c(1, 1, 1, 2), pch = c(1, 1, 1, NA))\n",
    "  dev.off()\n",
    "\n",
    "  message(sprintf(\"Done: %s → %s\", basename(csv_path), basename(out_path)))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7912326a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Done: AR_100_0.csv → AR_100_0_hw_h39_s0.csv\n",
      "\n",
      "Done: AR_1000_0.csv → AR_1000_0_hw_h390_s0.csv\n",
      "\n",
      "Done: AR_1000_0.csv → AR_1000_0_hw_h390_s0.csv\n",
      "\n",
      "Done: AR_10000_0.csv → AR_10000_0_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_0.csv → AR_10000_0_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_01.csv → AR_10000_01_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_01.csv → AR_10000_01_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_02.csv → AR_10000_02_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_02.csv → AR_10000_02_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_03.csv → AR_10000_03_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_10000_03.csv → AR_10000_03_hw_h3900_s0.csv\n",
      "\n",
      "Done: AR_50_0.csv → AR_50_0_hw_h20_s0.csv\n",
      "\n",
      "Done: AR_50_0.csv → AR_50_0_hw_h20_s0.csv\n",
      "\n",
      "Done: AR_500_0.csv → AR_500_0_hw_h195_s0.csv\n",
      "\n",
      "Done: AR_500_0.csv → AR_500_0_hw_h195_s0.csv\n",
      "\n",
      "Done: linear_100_0.csv → linear_100_0_hw_h39_s0.csv\n",
      "\n",
      "Done: linear_100_0.csv → linear_100_0_hw_h39_s0.csv\n",
      "\n",
      "Done: linear_1000_0.csv → linear_1000_0_hw_h390_s0.csv\n",
      "\n",
      "Done: linear_1000_0.csv → linear_1000_0_hw_h390_s0.csv\n",
      "\n",
      "Done: linear_10000_0.csv → linear_10000_0_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_0.csv → linear_10000_0_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_01.csv → linear_10000_01_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_01.csv → linear_10000_01_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_02.csv → linear_10000_02_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_02.csv → linear_10000_02_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_03.csv → linear_10000_03_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_10000_03.csv → linear_10000_03_hw_h3900_s0.csv\n",
      "\n",
      "Done: linear_50_0.csv → linear_50_0_hw_h20_s0.csv\n",
      "\n",
      "Done: linear_50_0.csv → linear_50_0_hw_h20_s0.csv\n",
      "\n",
      "Done: linear_500_0.csv → linear_500_0_hw_h195_s0.csv\n",
      "\n",
      "Done: linear_500_0.csv → linear_500_0_hw_h195_s0.csv\n",
      "\n",
      "Done: season_100_0.csv → season_100_0_hw_h39_s24.csv\n",
      "\n",
      "Done: season_100_0.csv → season_100_0_hw_h39_s24.csv\n",
      "\n",
      "Done: season_1000_0.csv → season_1000_0_hw_h390_s24.csv\n",
      "\n",
      "Done: season_1000_0.csv → season_1000_0_hw_h390_s24.csv\n",
      "\n",
      "Done: season_10000_0.csv → season_10000_0_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_0.csv → season_10000_0_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_01.csv → season_10000_01_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_01.csv → season_10000_01_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_02.csv → season_10000_02_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_02.csv → season_10000_02_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_03.csv → season_10000_03_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_10000_03.csv → season_10000_03_hw_h3900_s24.csv\n",
      "\n",
      "Done: season_50_0.csv → season_50_0_hw_h20_s24.csv\n",
      "\n",
      "Done: season_50_0.csv → season_50_0_hw_h20_s24.csv\n",
      "\n",
      "Done: season_500_0.csv → season_500_0_hw_h195_s24.csv\n",
      "\n",
      "Done: season_500_0.csv → season_500_0_hw_h195_s24.csv\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Process matching files\n",
    "files <- list.files(path = data_dir, pattern = glob2rx(name_glob), full.names = TRUE)\n",
    "for (f in sort(files)) {\n",
    "  tryCatch({\n",
    "    process_one(f)\n",
    "  }, error = function(e) {\n",
    "    message(sprintf(\"Failed %s: %s\", basename(f), e$message))\n",
    "  })\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
