{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90de578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import tracemalloc\n",
    "import time\n",
    "import json\n",
    "try:\n",
    "    import psutil\n",
    "    psutil_available = True\n",
    "    proc = psutil.Process()\n",
    "except Exception:\n",
    "    psutil_available = False\n",
    "    import resource\n",
    "\n",
    "def infer_file(data_dir: Path, file_arg: str = None) -> Path:\n",
    "    if file_arg:\n",
    "        f = Path(file_arg)\n",
    "        if not f.exists():\n",
    "            raise FileNotFoundError(f)\n",
    "        return f\n",
    "    files = sorted(data_dir.glob(\"*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files in {data_dir}\")\n",
    "    return files[0]\n",
    "\n",
    "def load_series(path: Path, y_col: str = \"y\"):\n",
    "    df = pd.read_csv(path)\n",
    "    if y_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{y_col}' not found in {path}\")\n",
    "    series = df[y_col].copy()\n",
    "\n",
    "    #series.index = pd.RangeIndex(start=0, stop=len(series), step=1)\n",
    "    \n",
    "    # If there's a 't' column and it's datetime-like, try to set index\n",
    "    if \"t\" in df.columns:\n",
    "        try:\n",
    "            idx = pd.to_datetime(df[\"t\"])\n",
    "            series.index = idx\n",
    "        except Exception:\n",
    "            series.index = pd.RangeIndex(start=0, stop=len(series), step=1)\n",
    "    else:\n",
    "        series.index = pd.RangeIndex(start=0, stop=len(series), step=1)\n",
    "    return series, df\n",
    "\n",
    "def make_future_index(index, h):\n",
    "    if isinstance(index, pd.DatetimeIndex):\n",
    "        freq = index.freq or pd.infer_freq(index)\n",
    "        if freq is None:\n",
    "            # fallback to daily\n",
    "            freq = \"D\"\n",
    "        return pd.date_range(start=index[-1] + pd.tseries.frequencies.to_offset(freq), periods=h, freq=freq)\n",
    "    else:\n",
    "        return np.arange(len(index), len(index) + h) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59885783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "project_root = Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "out_dir = project_root / \"output\" / \"python\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Selection pattern (glob) to filter files in data/\n",
    "# Example: only linear files with two numbers: linear_*_*.csv\n",
    "name_glob = \"season_USAccDeaths.csv\"  # change to e.g., \"linear_*_*.csv\" or \"season_*_*.csv\"\n",
    "\n",
    "# Config (set once for all files)\n",
    "seasonal_periods = None   # e.g., 12 for monthly seasonality\n",
    "trend = \"add\"             # \"add\", \"mul\", or \"none\"\n",
    "seasonal = \"add\"           # \"add\", \"mul\", or None\n",
    "ycol = \"y\"\n",
    "train_ratio = 0.7         # 70/30 split\"\n",
    "\n",
    "def calc_meme(train, test, tr, sn, sp, meme):\n",
    "    \n",
    "    # Train\n",
    "    if meme:\n",
    "        tracemalloc.start()\n",
    "        tracemalloc.reset_peak()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    model = ExponentialSmoothing(train, trend=tr, seasonal=sn, seasonal_periods=sp, initialization_method=\"estimated\")\n",
    "    fitted = model.fit(optimized=True)\n",
    "    train_time_s = time.perf_counter() - t0\n",
    "\n",
    "    if meme:\n",
    "        _, peak = tracemalloc.get_traced_memory()\n",
    "        mem_used_fit_bytes = peak\n",
    "    else:\n",
    "        mem_used_fit_bytes = 0\n",
    "\n",
    "    # Forecast\n",
    "    if meme:\n",
    "        tracemalloc.reset_peak()\n",
    "    t0 = time.perf_counter()\n",
    "    fcast = fitted.forecast(len(test))\n",
    "    predict_time_s = time.perf_counter() - t0\n",
    "\n",
    "    if meme:\n",
    "        _, peak = tracemalloc.get_traced_memory()\n",
    "        mem_used_pred_bytes = peak\n",
    "        tracemalloc.stop()\n",
    "    else:\n",
    "        mem_used_pred_bytes = 0\n",
    "\n",
    "\n",
    "    return fitted, fcast, train_time_s, predict_time_s, mem_used_fit_bytes, mem_used_pred_bytes\n",
    "\n",
    "def process_one(csv_path: Path):\n",
    "    series, raw_df = load_series(csv_path, ycol)\n",
    "    tr = None if trend == \"none\" else trend\n",
    "    sn = None if seasonal == \"none\" else seasonal\n",
    "    sp = seasonal_periods if sn else None\n",
    "    if sn and sp is None:\n",
    "        sp = 12\n",
    "\n",
    "    # Split\n",
    "    split = max(1, int(len(series) * train_ratio))\n",
    "    train = series.iloc[:split]\n",
    "    test = series.iloc[split:]\n",
    "\n",
    "    fitted, fcast, train_time_s, predict_time_s, mem_used_fit_bytes, mem_used_pred_bytes = calc_meme(train, test, tr, sn, sp, True)\n",
    "\n",
    "    # Index alignment: numeric index like source\n",
    "    if isinstance(series.index, pd.DatetimeIndex):\n",
    "        idx_vals = np.arange(len(series), len(series) + len(fcast))\n",
    "    else:\n",
    "        try:\n",
    "            idx_vals = fcast.index.astype(int)\n",
    "        except Exception:\n",
    "            idx_vals = np.arange(len(series), len(series) + len(fcast))\n",
    "\n",
    "    # Save forecast (index, value)\n",
    "    out_name = f\"{csv_path.stem}_hw_h{len(fcast)}_s{sp if sp else 0}.csv\"\n",
    "    out_path = out_dir / out_name\n",
    "    pd.DataFrame({\"index\": idx_vals, \"value\": fcast.values}).to_csv(out_path, index=False)\n",
    "\n",
    "    # Metrics JSON (matching requested schema)\n",
    "    y_true = test.values\n",
    "    y_pred = fcast.values\n",
    "    err = y_true - y_pred\n",
    "    rmse = float(np.sqrt(np.mean(err ** 2))) if len(test) else float(\"nan\")\n",
    "    mae = float(np.mean(np.abs(err))) if len(test) else float(\"nan\")\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        mape_arr = np.abs(err / np.where(y_true == 0, np.nan, y_true)) if len(test) else np.array([np.nan])\n",
    "        mape = float(np.nanmean(mape_arr) * 100)\n",
    "\n",
    "    metrics = {\n",
    "        \"file\": str(csv_path),\n",
    "        \"n_total\": int(len(series)),\n",
    "        \"n_train\": int(len(train)),\n",
    "        \"n_test\": int(len(test)),\n",
    "        \"train_time_s\": float(train_time_s),\n",
    "        \"predict_time_s\": float(predict_time_s),\n",
    "        \"mem_used_fit_bytes\": int(mem_used_fit_bytes),\n",
    "        \"mem_used_pred_bytes\": int(mem_used_pred_bytes),\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"mape_pct\": mape,\n",
    "        \"forecast_csv\": str(out_path),\n",
    "    }\n",
    "    metrics_path = out_dir / f\"{csv_path.stem}_hw_metrics.json\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train.index, train.values, label=\"train\", marker=\"o\")\n",
    "    plt.plot(test.index, test.values, label=\"test\", marker=\"o\")\n",
    "    plt.plot(train.index, fitted.fittedvalues, label=\"fitted (train)\", alpha=0.7)\n",
    "    try:\n",
    "        plt.plot(fcast.index, fcast.values, label=\"forecast\", marker=\"o\")\n",
    "    except Exception:\n",
    "        plt.plot(idx_vals, fcast.values, label=\"forecast\", marker=\"o\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Holt-Winters forecast ({csv_path.name})\")\n",
    "    plot_path = out_dir / f\"{csv_path.stem}_hw_plot_h{len(fcast)}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Done: {csv_path.name} → {out_path.name}, RMSE={rmse:.4f}, MAPE={mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68a41f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_USAccDeaths.csv → season_USAccDeaths_hw_h22_s12.csv, RMSE=408.2164, MAPE=3.45%\n"
     ]
    }
   ],
   "source": [
    "# Process CSVs in data matching glob pattern\n",
    "for csv in sorted(data_dir.glob(name_glob)):\n",
    "    try:\n",
    "        process_one(csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {csv.name}: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
