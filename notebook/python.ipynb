{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b90de578",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import tracemalloc\n",
    "import time\n",
    "import json\n",
    "try:\n",
    "    import psutil\n",
    "    psutil_available = True\n",
    "    proc = psutil.Process()\n",
    "except Exception:\n",
    "    psutil_available = False\n",
    "    import resource\n",
    "\n",
    "def infer_file(data_dir: Path, file_arg: str = None) -> Path:\n",
    "    if file_arg:\n",
    "        f = Path(file_arg)\n",
    "        if not f.exists():\n",
    "            raise FileNotFoundError(f)\n",
    "        return f\n",
    "    files = sorted(data_dir.glob(\"*.csv\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    if not files:\n",
    "        raise FileNotFoundError(f\"No CSV files in {data_dir}\")\n",
    "    return files[0]\n",
    "\n",
    "def load_series(path: Path, y_col: str = \"y\"):\n",
    "    df = pd.read_csv(path)\n",
    "    if y_col not in df.columns:\n",
    "        raise ValueError(f\"Column '{y_col}' not found in {path}\")\n",
    "    series = df[y_col].copy()\n",
    "\n",
    "    #series.index = pd.RangeIndex(start=0, stop=len(series), step=1)\n",
    "    \n",
    "    # If there's a 't' column and it's datetime-like, try to set index\n",
    "    if \"t\" in df.columns:\n",
    "        try:\n",
    "            idx = pd.to_datetime(df[\"t\"])\n",
    "            series.index = idx\n",
    "        except Exception:\n",
    "            series.index = pd.RangeIndex(start=0, stop=len(series), step=1)\n",
    "    else:\n",
    "        series.index = pd.RangeIndex(start=0, stop=len(series), step=1)\n",
    "    return series, df\n",
    "\n",
    "def make_future_index(index, h):\n",
    "    if isinstance(index, pd.DatetimeIndex):\n",
    "        freq = index.freq or pd.infer_freq(index)\n",
    "        if freq is None:\n",
    "            # fallback to daily\n",
    "            freq = \"D\"\n",
    "        return pd.date_range(start=index[-1] + pd.tseries.frequencies.to_offset(freq), periods=h, freq=freq)\n",
    "    else:\n",
    "        return np.arange(len(index), len(index) + h) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59885783",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "project_root = Path.cwd().resolve().parent\n",
    "data_dir = project_root / \"data\"\n",
    "out_dir = project_root / \"output\" / \"python\"\n",
    "data_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Selection pattern (glob) to filter files in data/\n",
    "# Example: only linear files with two numbers: linear_*_*.csv\n",
    "name_glob = \"season_mul*.csv\"  # change to e.g., \"linear_*_*.csv\" or \"season_*_*.csv\"\n",
    "\n",
    "# Config (set once for all files)\n",
    "seasonal_periods = 24   # e.g., 12 for monthly seasonality\n",
    "trend = \"add\"             # \"add\", \"mul\", or \"none\"\n",
    "seasonal = \"mul\"           # \"add\", \"mul\", or None\n",
    "ycol = \"y\"\n",
    "train_ratio = 0.7         # 70/30 split\"\n",
    "\n",
    "def calc_meme(train, test, tr, sn, sp, meme):\n",
    "    \n",
    "    # Train\n",
    "    if meme:\n",
    "        tracemalloc.start()\n",
    "        tracemalloc.reset_peak()\n",
    "\n",
    "    t0 = time.perf_counter()\n",
    "    model = ExponentialSmoothing(train, trend=tr, seasonal=sn, seasonal_periods=sp, initialization_method=\"estimated\")\n",
    "    fitted = model.fit(optimized=True)\n",
    "    train_time_s = time.perf_counter() - t0\n",
    "\n",
    "    if meme:\n",
    "        _, peak = tracemalloc.get_traced_memory()\n",
    "        mem_used_fit_bytes = peak\n",
    "    else:\n",
    "        mem_used_fit_bytes = 0\n",
    "\n",
    "    # Forecast\n",
    "    if meme:\n",
    "        tracemalloc.reset_peak()\n",
    "    t0 = time.perf_counter()\n",
    "    fcast = fitted.forecast(len(test))\n",
    "    predict_time_s = time.perf_counter() - t0\n",
    "\n",
    "    if meme:\n",
    "        _, peak = tracemalloc.get_traced_memory()\n",
    "        mem_used_pred_bytes = peak\n",
    "        tracemalloc.stop()\n",
    "    else:\n",
    "        mem_used_pred_bytes = 0\n",
    "\n",
    "\n",
    "    return fitted, fcast, train_time_s, predict_time_s, mem_used_fit_bytes, mem_used_pred_bytes\n",
    "\n",
    "def process_one(csv_path: Path):\n",
    "    series, raw_df = load_series(csv_path, ycol)\n",
    "    tr = None if trend == \"none\" else trend\n",
    "    sn = None if seasonal == \"none\" else seasonal\n",
    "    sp = seasonal_periods if sn else None\n",
    "    meme = False\n",
    "    if sn and sp is None:\n",
    "        sp = 24\n",
    "\n",
    "    # Split\n",
    "    split = max(1, int(len(series) * train_ratio))\n",
    "    train = series.iloc[:split]\n",
    "    test = series.iloc[split:]\n",
    "\n",
    "    fitted, fcast, train_time_s, predict_time_s, mem_used_fit_bytes, mem_used_pred_bytes = calc_meme(train, test, tr, sn, sp, meme)\n",
    "\n",
    "    # Index alignment: numeric index like source\n",
    "    if isinstance(series.index, pd.DatetimeIndex):\n",
    "        idx_vals = np.arange(len(series), len(series) + len(fcast))\n",
    "    else:\n",
    "        try:\n",
    "            idx_vals = fcast.index.astype(int)\n",
    "        except Exception:\n",
    "            idx_vals = np.arange(len(series), len(series) + len(fcast))\n",
    "\n",
    "    # Save forecast (index, value)\n",
    "    out_name = f\"{csv_path.stem}_hw_h{len(fcast)}_s{sp if sp else 0}.csv\"\n",
    "    out_path = out_dir / out_name\n",
    "    pd.DataFrame({\"index\": idx_vals, \"value\": fcast.values}).to_csv(out_path, index=False)\n",
    "\n",
    "    # Metrics JSON (matching requested schema)\n",
    "    y_true = test.values\n",
    "    y_pred = fcast.values\n",
    "    err = y_true - y_pred\n",
    "    rmse = float(np.sqrt(np.mean(err ** 2))) if len(test) else float(\"nan\")\n",
    "    mae = float(np.mean(np.abs(err))) if len(test) else float(\"nan\")\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        if sn == \"mul\":\n",
    "            den = (np.abs(y_true) + np.abs(y_pred)) / 2.0\n",
    "            mape = float(np.nanmean(np.abs(err) / np.where(den < 1e-8, np.nan, den)) * 100)\n",
    "        else:\n",
    "            mape_arr = np.abs(err / np.where(y_true == 0, np.nan, y_true)) if len(test) else np.array([np.nan])\n",
    "            mape = float(np.nanmean(mape_arr) * 100)\n",
    "\n",
    "    metrics = {\n",
    "        \"file\": str(csv_path),\n",
    "        \"n_total\": int(len(series)),\n",
    "        \"n_train\": int(len(train)),\n",
    "        \"n_test\": int(len(test)),\n",
    "        \"train_time_s\": float(train_time_s),\n",
    "        \"predict_time_s\": float(predict_time_s),\n",
    "        \"mem_used_fit_bytes\": int(mem_used_fit_bytes),\n",
    "        \"mem_used_pred_bytes\": int(mem_used_pred_bytes),\n",
    "        \"rmse\": rmse,\n",
    "        \"mae\": mae,\n",
    "        \"mape_pct\": mape,\n",
    "        \"forecast_csv\": str(out_path),\n",
    "    }\n",
    "    metrics_path = out_dir / f\"{csv_path.stem}_hw_metrics.json\"\n",
    "    with open(metrics_path, \"w\") as f:\n",
    "        json.dump(metrics, f, indent=2)\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train.index, train.values, label=\"train\", marker=\"o\")\n",
    "    plt.plot(test.index, test.values, label=\"test\", marker=\"o\")\n",
    "    plt.plot(train.index, fitted.fittedvalues, label=\"fitted (train)\", alpha=0.7)\n",
    "    try:\n",
    "        plt.plot(fcast.index, fcast.values, label=\"forecast\", marker=\"o\")\n",
    "    except Exception:\n",
    "        plt.plot(idx_vals, fcast.values, label=\"forecast\", marker=\"o\")\n",
    "    plt.legend()\n",
    "    plt.title(f\"Holt-Winters forecast ({csv_path.name})\")\n",
    "    plot_path = out_dir / f\"{csv_path.stem}_hw_plot_h{len(fcast)}.png\"\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(plot_path)\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"Done: {csv_path.name} → {out_path.name}, RMSE={rmse:.4f}, MAPE={mape:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68a41f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_10000_0.csv → season_mul_10000_0_hw_h3900_s24.csv, RMSE=1.0065, MAPE=0.01%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_10000_01.csv → season_mul_10000_01_hw_h3900_s24.csv, RMSE=12469.7528, MAPE=1.99%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_10000_02.csv → season_mul_10000_02_hw_h3900_s24.csv, RMSE=18250.8767, MAPE=6.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n",
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/holtwinters/model.py:918: ConvergenceWarning: Optimization failed to converge. Check mle_retvals.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_10000_03.csv → season_mul_10000_03_hw_h3900_s24.csv, RMSE=22242.9110, MAPE=7.96%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_1000_0.csv → season_mul_1000_0_hw_h391_s24.csv, RMSE=1.0489, MAPE=0.11%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_100_0.csv → season_mul_100_0_hw_h39_s24.csv, RMSE=1.0969, MAPE=1.04%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done: season_mul_500_0.csv → season_mul_500_0_hw_h196_s24.csv, RMSE=1.1661, MAPE=0.25%\n",
      "Failed season_mul_50_0.csv: Cannot compute initial seasonals using heuristic method with less than two full seasonal cycles in the data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: No frequency information was provided, so inferred frequency ns will be used.\n",
      "  self._init_dates(dates, freq)\n"
     ]
    }
   ],
   "source": [
    "# Process CSVs in data matching glob pattern\n",
    "for csv in sorted(data_dir.glob(name_glob)):\n",
    "    try:\n",
    "        process_one(csv)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed {csv.name}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33149330",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'air' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 21\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# AirPassengers (ручная загрузка — канонично)\u001b[39;00m\n\u001b[1;32m      6\u001b[0m air_passengers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;241m112\u001b[39m,\u001b[38;5;241m118\u001b[39m,\u001b[38;5;241m132\u001b[39m,\u001b[38;5;241m129\u001b[39m,\u001b[38;5;241m121\u001b[39m,\u001b[38;5;241m135\u001b[39m,\u001b[38;5;241m148\u001b[39m,\u001b[38;5;241m148\u001b[39m,\u001b[38;5;241m136\u001b[39m,\u001b[38;5;241m119\u001b[39m,\u001b[38;5;241m104\u001b[39m,\u001b[38;5;241m118\u001b[39m,\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;241m115\u001b[39m,\u001b[38;5;241m126\u001b[39m,\u001b[38;5;241m141\u001b[39m,\u001b[38;5;241m135\u001b[39m,\u001b[38;5;241m125\u001b[39m,\u001b[38;5;241m149\u001b[39m,\u001b[38;5;241m170\u001b[39m,\u001b[38;5;241m170\u001b[39m,\u001b[38;5;241m158\u001b[39m,\u001b[38;5;241m133\u001b[39m,\u001b[38;5;241m114\u001b[39m,\u001b[38;5;241m140\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;241m417\u001b[39m,\u001b[38;5;241m391\u001b[39m,\u001b[38;5;241m419\u001b[39m,\u001b[38;5;241m461\u001b[39m,\u001b[38;5;241m472\u001b[39m,\u001b[38;5;241m535\u001b[39m,\u001b[38;5;241m622\u001b[39m,\u001b[38;5;241m606\u001b[39m,\u001b[38;5;241m508\u001b[39m,\u001b[38;5;241m461\u001b[39m,\u001b[38;5;241m390\u001b[39m,\u001b[38;5;241m432\u001b[39m\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 21\u001b[0m y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mair\u001b[49m, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# ---------- train / test ----------\u001b[39;00m\n\u001b[1;32m     24\u001b[0m split \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(y) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.7\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'air' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "\n",
    "# AirPassengers (ручная загрузка — канонично)\n",
    "air = [\n",
    "    112,118,132,129,121,135,148,148,136,119,104,118,\n",
    "    115,126,141,135,125,149,170,170,158,133,114,140,\n",
    "    145,150,178,163,172,178,199,199,184,162,146,166,\n",
    "    171,180,193,181,183,218,230,242,209,191,172,194,\n",
    "    196,196,236,235,229,243,264,272,237,211,180,201,\n",
    "    204,188,235,227,234,264,302,293,259,229,203,229,\n",
    "    242,233,267,269,270,315,364,347,312,274,237,278,\n",
    "    284,277,317,313,318,374,413,405,355,306,271,306,\n",
    "    315,301,356,348,355,422,465,467,404,347,305,336,\n",
    "    340,318,362,348,363,435,491,505,404,359,310,337,\n",
    "    360,342,406,396,420,472,548,559,463,407,362,405,\n",
    "    417,391,419,461,472,535,622,606,508,461,390,432\n",
    "]\n",
    "\n",
    "y = np.array(air, dtype=float)\n",
    "\n",
    "# ---------- train / test ----------\n",
    "split = int(len(y) * 0.7)\n",
    "train = y[:split]\n",
    "test = y[split:]\n",
    "\n",
    "proc = psutil.Process()\n",
    "\n",
    "# ---------- FIT ----------\n",
    "mem_before = proc.memory_info().rss\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "model = ExponentialSmoothing(\n",
    "    train,\n",
    "    trend=\"add\",\n",
    "    seasonal=\"mul\",\n",
    "    seasonal_periods=12\n",
    ")\n",
    "fitted = model.fit()\n",
    "\n",
    "time_fit = time.perf_counter() - t0\n",
    "mem_fit = proc.memory_info().rss - mem_before\n",
    "\n",
    "# ---------- PREDICT ----------\n",
    "mem_before = proc.memory_info().rss\n",
    "t0 = time.perf_counter()\n",
    "\n",
    "pred = fitted.forecast(len(test))\n",
    "\n",
    "time_pred = time.perf_counter() - t0\n",
    "mem_pred = proc.memory_info().rss - mem_before\n",
    "\n",
    "# ---------- METRICS ----------\n",
    "err = test - pred\n",
    "rmse = np.sqrt(np.mean(err**2))\n",
    "mae = np.mean(np.abs(err))\n",
    "mape = np.mean(np.abs(err / test)) * 100\n",
    "\n",
    "# ---------- TABLE ----------\n",
    "table = pd.DataFrame({\n",
    "    \"Lang\": [\"Python\"],\n",
    "    \"Time fit\": [round(time_fit, 3)],\n",
    "    \"Time pred\": [round(time_pred, 3)],\n",
    "    \"Mem fit\": [mem_fit],\n",
    "    \"Mem pred\": [mem_pred],\n",
    "    \"RMSE\": [round(rmse, 2)],\n",
    "    \"MAE\": [round(mae, 2)],\n",
    "    \"MAPE\": [round(mape, 3)]\n",
    "})\n",
    "\n",
    "table\n",
    "\n",
    "# График\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(train.index, train[\"y\"], label=\"train\")\n",
    "plt.plot(test.index, test[\"y\"], label=\"test\")\n",
    "plt.plot(train.index, fitted.fittedvalues, label=\"fitted (train)\")\n",
    "plt.plot(test.index, forecast, label=\"forecast\")\n",
    "plt.legend()\n",
    "plt.title(\"Holt–Winters forecast (AirPassengers, Python)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
